{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "553UZ1iuVOV7"
      },
      "source": [
        "# TP4, INF8225 2025, Projet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDjWK-m8VOV8"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XSGJpgj7VOV8"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
        "%pip install numpy\n",
        "%pip install swig\n",
        "%pip install box2d\n",
        "%pip install pygame\n",
        "%pip install gymnasium\n",
        "%pip install \"gymnasium[box2d]\"\n",
        "%pip install matplotlib\n",
        "%pip install wandb\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "fcRnqGzMVOV8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "import matplotlib.animation as animation\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as T\n",
        "import random\n",
        "import os\n",
        "import wandb\n",
        "from IPython.display import clear_output\n",
        "import math\n",
        "from collections import namedtuple, deque"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28fvb3eqVOV8"
      },
      "source": [
        "### Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2wOLXAUVOV8",
        "outputId": "8867c865-36b6-4ef6-c652-c0249d8df724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "12.1\n",
            "NVIDIA GeForce GTX 1050\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(torch.version.cuda)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "\tprint(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCvxsgx4VOV8"
      },
      "source": [
        "## Data Declaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2GvSSPqVOV8",
        "outputId": "c8d847fb-97bc-4aa1-b411-c2083a3ef21b"
      },
      "outputs": [],
      "source": [
        "def show_animation(env):\n",
        "\tshow_animation_frames(env.render())\n",
        "\n",
        "def show_animation_frames(frames):\n",
        "\tfig = plt.figure(figsize=(7, 5))\n",
        "\tplt.axis('off')\n",
        "\tim = plt.imshow(frames[0])\n",
        "\n",
        "\tdef animate(i):\n",
        "\t\tim.set_data(frames[i])\n",
        "\t\treturn im,\n",
        "\n",
        "\tanim = animation.FuncAnimation(fig, animate, frames=len(frames), repeat=False)\n",
        "\tplt.close(fig)\n",
        "\tdisplay(HTML(anim.to_jshtml()))\n",
        "\n",
        "def show_current_frame(env, data):\n",
        "\tframe = env.render()\n",
        "\tfig, _ = plt.subplots()\n",
        "\tr = fig.canvas.get_renderer()\n",
        "\tplt.imshow(frame)\n",
        "\tplt.axis('off')\n",
        "\ttexts = []\n",
        "\tsize_used = 0\n",
        "\tfor i, key in enumerate(data):\n",
        "\t\ttitle = f'{key}: {data[key]}'\n",
        "\t\tif type(data[key]) == float or type(data[key]) == torch.Tensor:\n",
        "\t\t\ttitle = f'{key}: {data[key]:.2f}'\n",
        "\t\ttext = plt.text(0, 0, title, fontsize=12, color='black', backgroundcolor='white', ha=\"center\")\n",
        "\t\tsize_used += text.get_window_extent(renderer=r).width\n",
        "\t\ttexts.append(text)\n",
        "\tsplit = (700 - size_used) / (len(data) + 1)\n",
        "\tnext_position = split\n",
        "\tfor t in texts:\n",
        "\t\tt.set_position((next_position, 0))\n",
        "\t\tnext_position = next_position + t.get_window_extent(renderer=r).width + split\n",
        "\tclear_output(wait=True)\n",
        "\tplt.show()\n",
        "\n",
        "def skip_zooming(env):\n",
        "\tno_action = 0\n",
        "\tif type(env.action_space) != gym.spaces.Discrete:\n",
        "\t\tno_action = np.zeros((env.action_space.shape[0]))\n",
        "\n",
        "\tfor _ in range(50):\n",
        "\t\tobservation, _, terminated, truncated, info = env.step(no_action)\n",
        "\n",
        "\t\tif terminated or truncated:\n",
        "\t\t\tobservation, info = env.reset()\n",
        "\t\t\tbreak\n",
        "\treturn observation, info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYfc-8GFVOV9"
      },
      "source": [
        "### Helper Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "KSkwQhR8VOV9"
      },
      "outputs": [],
      "source": [
        "transform = T.Compose([\n",
        "\tT.ToPILImage(),\n",
        "\tT.Grayscale(num_output_channels=1),\n",
        "\tT.Resize((84, 84)),\n",
        "\tT.ToTensor(),\n",
        "\tT.Normalize((0.5,), (0.5,))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XooYEygsVOV9"
      },
      "source": [
        "## Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALVCgGGoVOV9"
      },
      "source": [
        "### DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6co9R30VVOV9"
      },
      "source": [
        "#### Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIRvRtvxVOV9"
      },
      "source": [
        "DQN is at its heart Q-Learning using Deep Neural Networks to predict the behavior of its environment and to predict which action is the best.\n",
        "\n",
        "Our goal, when implementing DQN is to maximize the rewards of our policy $\\pi^{*}$ described as followed, where $Q^{*}$ is defined as the optimal action-value function.\n",
        "\n",
        "$$\n",
        "\\pi^{*}(s) = \\underset{a}{\\arg\\max} \\; Q^{*}(s,a)\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "The definition of $Q^{*}$ follows the Bellman Optimality Equation:\n",
        "\n",
        "$$\n",
        "Q^{*}(s,a) = \\mathbb{E} \\left[ r + \\gamma \\underset{a'}{\\max} Q^{*}(s', a') \\; | \\; s, a \\right]\n",
        "$$\n",
        "\n",
        "The equation means that the value of an action is dictated by the current reward + the best reward we can get from the best next action. The $\\gamma$ symbol is used only so that we can diminishes the importance of futur action on the long run.\n",
        "\n",
        "Our goal is to maximize the rewards we will have on the long term, which can be defined as:\n",
        "\n",
        "$$\n",
        "G_t = r_t + \\gamma r_{t+1} + \\gamma^{2} r_{t+2} + \\gamma^{3} r_{t+3} + ...  \n",
        "$$\n",
        "\n",
        "Based on Bellman's Optimality Equation, we are able to use the following update equation:\n",
        "\n",
        "$$\n",
        "Q(s,a) \\leftarrow Q(s,a) + \\alpha \\left[r + \\gamma \\underset{a'}{\\max}Q(s', a') - Q(s,a) \\right]\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZunLW1MVOV9"
      },
      "source": [
        "#### Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Jd0qR4DEVOV9"
      },
      "outputs": [],
      "source": [
        "# Implementation based on : https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
        "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward', 'done'))\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\tdef __init__(self, capacity):\n",
        "\t\tself.memory = deque([], maxlen=capacity)\n",
        "\n",
        "\tdef append(self, *args):\n",
        "\t\t\"\"\"Save a transition\"\"\"\n",
        "\t\tself.memory.append(Transition(*args))\n",
        "\n",
        "\tdef sample(self, batch_size):\n",
        "\t\treturn random.sample(self.memory, batch_size)\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.memory)\n",
        "\n",
        "class DQN(nn.Module):\n",
        "\tdef __init__(self, n_actions):\n",
        "\t\t\"\"\"\n",
        "\t\tQ-Network made of a Deep neural network\n",
        "\t\t\"\"\"\n",
        "\t\tsuper(DQN, self).__init__()\n",
        "\t\t# TODO: Ajust the depth of the model so that we don't need to use 128 each time,\n",
        "\t\t# and evaluate the impact of changing those values\n",
        "\t\tself.net = nn.Sequential(\n",
        "\t\t\t# Adjusted for RGB input (84x84x1) without resizing\n",
        "\t\t\tnn.Conv2d(1, 32, kernel_size=8, stride=4),    # Output: 32x23x23\n",
        "\t\t\tnn.ReLU(),\n",
        "\t\t\tnn.Conv2d(32, 64, kernel_size=4, stride=2),   # Output: 64x10x10\n",
        "\t\t\tnn.ReLU(),\n",
        "\t\t\tnn.Conv2d(64, 64, kernel_size=3, stride=1),    # Output: 64x8x8\n",
        "\t\t\tnn.ReLU(),\n",
        "\t\t\tnn.Flatten(),\n",
        "\t\t\tnn.Linear(64 * 7 * 7, 1024),\n",
        "\t\t\tnn.ReLU(),\n",
        "\t\t\tnn.Linear(1024, 512),\n",
        "\t\t\tnn.ReLU(),\n",
        "\t\t\tnn.Linear(512, n_actions)\n",
        "\t\t)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\treturn self.net(x)\n",
        "\n",
        "class DQNAgent():\n",
        "\tdef __init__(self, env, save_path=\"dqn.pth\", lr=3e-4, gamma=0.95, batch_size=64, memory_size=5000, epsilon_start=0.8, epsilon_end=0.2, epsilon_decay=1000):\n",
        "\t\t\"\"\"\n",
        "\t\tAgent made of DQNs used for learning how to use the sim racer.\n",
        "\t\t\"\"\"\n",
        "\t\tself.save_path = save_path\n",
        "\n",
        "\t\t# Hyperparameters\n",
        "\t\tself.GAMMA = gamma\n",
        "\t\tself.LR = lr\n",
        "\t\tself.BATCH_SIZE = batch_size\n",
        "\t\tself.MEMORY_SIZE = memory_size\n",
        "\t\tself.EPSILON_DECAY = epsilon_decay\n",
        "\n",
        "\t\tself.n_actions = env.action_space.n\n",
        "\n",
        "\t\t# Neural Network Declarations Here\n",
        "\t\tself.policy_net = DQN(self.n_actions).to(device)\n",
        "\t\tself.target_net = DQN(self.n_actions).to(device)\n",
        "\t\tself.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "\n",
        "\t\tself.optimizer = optim.AdamW(self.policy_net.parameters(), lr=self.LR, amsgrad=True)\n",
        "\t\tself.memory = ReplayMemory(self.MEMORY_SIZE)\n",
        "\n",
        "\t\tself.epsilon = epsilon_start\n",
        "\t\tself.epsilon_max = epsilon_start\n",
        "\t\tself.epsilon_min = epsilon_end\n",
        "\t\tself.epsilon_decay = (self.epsilon_max - self.epsilon_min) / memory_size\n",
        "\n",
        "\tdef save(self):\n",
        "\t\ttry:\n",
        "\t\t\ttorch.save({ 'policy_net_state_dict': self.policy_net.state_dict(), 'target_net_state_dict': self.target_net.state_dict() }, self.save_path)\n",
        "\t\texcept:\n",
        "\t\t\treturn\n",
        "\n",
        "\tdef load(self):\n",
        "\t\tif os.path.isfile(self.save_path):\n",
        "\t\t\tcheckpoint = torch.load(self.save_path, map_location=device)\n",
        "\t\t\tself.policy_net.load_state_dict(checkpoint['policy_net_state_dict'])\n",
        "\t\t\tself.target_net.load_state_dict(checkpoint['target_net_state_dict'])\n",
        "\n",
        "\tdef select_action(self, state):\n",
        "\t\t\"\"\"\n",
        "\t\tEpsilon-greedy strategy\n",
        "\n",
        "\t\tstate: contains the rgb image of the car and the racing track (96, 96, 3)\n",
        "\t\t\"\"\"\n",
        "\t\tsample = random.random()\n",
        "\t\tif sample > self.epsilon:\n",
        "\t\t\twith torch.no_grad():\n",
        "\t\t\t\t# Add batch dimension and convert to float\n",
        "\t\t\t\tstate_tensor = state.unsqueeze(0).float().to(device)\n",
        "\t\t\t\tq_values = self.policy_net(state_tensor)\n",
        "\t\t\t\taction_idx = q_values.argmax().item()\n",
        "\t\telse:\n",
        "\t\t\taction_idx = random.randint(0, self.n_actions-1)\n",
        "\n",
        "\t\tself.epsilon = max(self.epsilon - self.epsilon_decay, self.epsilon_min)\n",
        "\t\treturn action_idx, self.epsilon\n",
        "\n",
        "\tdef optimize_model(self):\n",
        "\t\t\"\"\"\n",
        "\t\tApply the backward propagation to the policy_net and the target_net.\n",
        "\t\t\"\"\"\n",
        "\t\tif len(self.memory) < self.BATCH_SIZE:\n",
        "\t\t\treturn\n",
        "\n",
        "\t\ttransitions = self.memory.sample(self.BATCH_SIZE)\n",
        "\t\tbatch = Transition(*zip(*transitions))\n",
        "\n",
        "\t\tstates = torch.stack([s for s in batch.state]).to(device)\n",
        "\t\tactions = torch.tensor(batch.action, dtype=torch.long, device=device)\n",
        "\t\trewards = torch.tensor(batch.reward, dtype=torch.float32, device=device).unsqueeze(1)\n",
        "\t\tdones = torch.tensor(batch.done, dtype=torch.bool, device=device).unsqueeze(1)\n",
        "\t\tnext_states = torch.stack([s for s in batch.next_state]).to(device)\n",
        "\n",
        "\t\t# Remove flattening steps to keep spatial structure\n",
        "\t\tcurrent_q = self.policy_net(states).gather(1, actions.unsqueeze(1))\n",
        "\t\tnext_q = self.target_net(next_states).max(1)[0].unsqueeze(1)\n",
        "\t\texpected_q = rewards + (self.GAMMA * next_q * ~dones)\n",
        "\n",
        "\t\tloss = nn.SmoothL1Loss()(current_q, expected_q)\n",
        "\n",
        "\t\tself.optimizer.zero_grad()\n",
        "\t\tloss.backward()\n",
        "\t\t# In-place gradient clipping\n",
        "\t\ttorch.nn.utils.clip_grad_value_(self.policy_net.parameters(), 100)\n",
        "\t\tself.optimizer.step()\n",
        "\n",
        "\t\treturn loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teWHBJfaVOV9"
      },
      "source": [
        "#### Training Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN27iuFcjdrl"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "\t\"seed\": 42,\n",
        "\t\"max_episodes\": 300000,\n",
        "\t\"max_timesteps\": 10000,\n",
        "\t\"continuous\": False,\n",
        "\t\"load_save\": False,\n",
        "\t\"lap_complete_percent\": 0.95,\n",
        "\t\"max_losing_step\": 100,\n",
        "\t\"lr\": 3e-4,\n",
        "\t\"gamma\": 0.99,\n",
        "\t\"batch_size\": 32,\n",
        "\t\"memory_size\": 100000,\n",
        "\t\"epsilon_start\": 1.0,\n",
        "\t\"epsilon_end\": 0.1,\n",
        "\t\"epsilon_decay\": 0.05,\n",
        "\t\"stop_criteria_count\": 10,\n",
        "\t\"target_update_freq\": 5,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "iljGLxzoVOV9",
        "outputId": "bff924d1-ba43-481e-cd99-ec56d0d99799"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Alexandre\\AppData\\Local\\Temp\\ipykernel_27944\\1510050613.py\", line 26, in <module>\n",
            "    next_state, reward, done, truncated, _ = env.step(action_idx)\n",
            "                                             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\Repo_Git\\INF8225\\.venv\\Lib\\site-packages\\gymnasium\\wrappers\\common.py\", line 125, in step\n",
            "    observation, reward, terminated, truncated, info = self.env.step(action)\n",
            "                                                       ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\Repo_Git\\INF8225\\.venv\\Lib\\site-packages\\gymnasium\\wrappers\\common.py\", line 393, in step\n",
            "    return super().step(action)\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\Repo_Git\\INF8225\\.venv\\Lib\\site-packages\\gymnasium\\core.py\", line 327, in step\n",
            "    return self.env.step(action)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\Repo_Git\\INF8225\\.venv\\Lib\\site-packages\\gymnasium\\wrappers\\common.py\", line 285, in step\n",
            "    return self.env.step(action)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\Repo_Git\\INF8225\\.venv\\Lib\\site-packages\\gymnasium\\envs\\box2d\\car_racing.py\", line 563, in step\n",
            "    self.state = self._render(\"state_pixels\")\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\Repo_Git\\INF8225\\.venv\\Lib\\site-packages\\gymnasium\\envs\\box2d\\car_racing.py\", line 628, in _render\n",
            "    self._render_road(zoom, trans, angle)\n",
            "  File \"d:\\Repo_Git\\INF8225\\.venv\\Lib\\site-packages\\gymnasium\\envs\\box2d\\car_racing.py\", line 698, in _render_road\n",
            "    self._draw_colored_polygon(self.surf, poly, color, zoom, translation, angle)\n",
            "  File \"d:\\Repo_Git\\INF8225\\.venv\\Lib\\site-packages\\gymnasium\\envs\\box2d\\car_racing.py\", line 785, in _draw_colored_polygon\n",
            "    gfxdraw.aapolygon(self.surf, poly, color)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>current_reward</td><td>▇▅▅██▇▇▆▇▇▅▅▅█▇▇▆▇█▇▇█▇▄▇█▅█▅█▅▁█▇▇▇▆▇▇▆</td></tr><tr><td>done</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epsilon</td><td>█████▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▁▁▁▁▁</td></tr><tr><td>loss</td><td>▁▁▁▄▁▁▁▁▆▁▃▄▆▁▁▁▄▁▁▁▄▁▁▄▁█▁▁▁▁▁▃▁▁▁▁▁▁▃▄</td></tr><tr><td>reward</td><td>▄▇▇▇▆▁▅▇▇▆█▇▃▆▅▆▁█▇▇▆▇▆▇█</td></tr><tr><td>timestep</td><td>▃▁▂▁▂▁▂▂▆▇█▁▂▃▁▂▂▃▄▄▁▃▂▆▆▁▂▂▁▂▁▂▂▂▃▁▁▂▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>current_reward</td><td>-20.99929</td></tr><tr><td>done</td><td>0</td></tr><tr><td>episode</td><td>24</td></tr><tr><td>epsilon</td><td>0.93646</td></tr><tr><td>loss</td><td>0.00091</td></tr><tr><td>reward</td><td>-8.96643</td></tr><tr><td>timestep</td><td>315</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lemon-dawn-100</strong> at: <a href='https://wandb.ai/lexore-poly/INF8225%20-%20TP4/runs/u7twib67' target=\"_blank\">https://wandb.ai/lexore-poly/INF8225%20-%20TP4/runs/u7twib67</a><br> View project at: <a href='https://wandb.ai/lexore-poly/INF8225%20-%20TP4' target=\"_blank\">https://wandb.ai/lexore-poly/INF8225%20-%20TP4</a><br>Synced 6 W&B file(s), 25 media file(s), 3 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20250424_160732-u7twib67\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[36], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m     25\u001b[0m \taction_idx, epsilon \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mselect_action(state)\n\u001b[1;32m---> 26\u001b[0m \tnext_state, reward, done, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \tdone \u001b[38;5;241m=\u001b[39m done \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[0;32m     29\u001b[0m \tnext_state \u001b[38;5;241m=\u001b[39m transform(next_state)\n",
            "File \u001b[1;32md:\\Repo_Git\\INF8225\\.venv\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:125\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[0;32m    114\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m \n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
            "File \u001b[1;32md:\\Repo_Git\\INF8225\\.venv\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:393\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Repo_Git\\INF8225\\.venv\\Lib\\site-packages\\gymnasium\\core.py:327\u001b[0m, in \u001b[0;36mWrapper.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[0;32m    325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Repo_Git\\INF8225\\.venv\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:285\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Repo_Git\\INF8225\\.venv\\Lib\\site-packages\\gymnasium\\envs\\box2d\\car_racing.py:563\u001b[0m, in \u001b[0;36mCarRacing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mStep(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS, \u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS\n\u001b[1;32m--> 563\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_pixels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m step_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    566\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[1;32md:\\Repo_Git\\INF8225\\.venv\\Lib\\site-packages\\gymnasium\\envs\\box2d\\car_racing.py:628\u001b[0m, in \u001b[0;36mCarRacing._render\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    625\u001b[0m trans \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mVector2((scroll_x, scroll_y))\u001b[38;5;241m.\u001b[39mrotate_rad(angle)\n\u001b[0;32m    626\u001b[0m trans \u001b[38;5;241m=\u001b[39m (WINDOW_W \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m trans[\u001b[38;5;241m0\u001b[39m], WINDOW_H \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m+\u001b[39m trans[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 628\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_road\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcar\u001b[38;5;241m.\u001b[39mdraw(\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf,\n\u001b[0;32m    631\u001b[0m     zoom,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    634\u001b[0m     mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_pixels_list\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_pixels\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    635\u001b[0m )\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mflip(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[1;32md:\\Repo_Git\\INF8225\\.venv\\Lib\\site-packages\\gymnasium\\envs\\box2d\\car_racing.py:698\u001b[0m, in \u001b[0;36mCarRacing._render_road\u001b[1;34m(self, zoom, translation, angle)\u001b[0m\n\u001b[0;32m    696\u001b[0m poly \u001b[38;5;241m=\u001b[39m [(p[\u001b[38;5;241m0\u001b[39m], p[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m poly]\n\u001b[0;32m    697\u001b[0m color \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m color]\n\u001b[1;32m--> 698\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_colored_polygon\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Repo_Git\\INF8225\\.venv\\Lib\\site-packages\\gymnasium\\envs\\box2d\\car_racing.py:785\u001b[0m, in \u001b[0;36mCarRacing._draw_colored_polygon\u001b[1;34m(self, surface, poly, color, zoom, translation, angle, clip)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;66;03m# This checks if the polygon is out of bounds of the screen, and we skip drawing if so.\u001b[39;00m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;66;03m# Instead of calculating exactly if the polygon and screen overlap,\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# we simply check if the polygon is in a larger bounding box whose dimension\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;66;03m# is greater than the screen by MAX_SHAPE_DIM, which is the maximum\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;66;03m# diagonal length of an environment object\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m clip \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    781\u001b[0m     (\u001b[38;5;241m-\u001b[39mMAX_SHAPE_DIM \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m coord[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m WINDOW_W \u001b[38;5;241m+\u001b[39m MAX_SHAPE_DIM)\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m-\u001b[39mMAX_SHAPE_DIM \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m coord[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m WINDOW_H \u001b[38;5;241m+\u001b[39m MAX_SHAPE_DIM)\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m coord \u001b[38;5;129;01min\u001b[39;00m poly\n\u001b[0;32m    784\u001b[0m ):\n\u001b[1;32m--> 785\u001b[0m     \u001b[43mgfxdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maapolygon\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    786\u001b[0m     gfxdraw\u001b[38;5;241m.\u001b[39mfilled_polygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, poly, color)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "with wandb.init(\n",
        "\t\tconfig=config,\n",
        "\t\tproject='INF8225 - TP4',\n",
        "\t\tgroup='DQN',\n",
        "\t\tsave_code=True,\n",
        "\t\tmode=\"online\"\n",
        "\t):\n",
        "\t# Training loop\n",
        "\tenv = gym.make(\"CarRacing-v3\", render_mode=\"rgb_array\", domain_randomize=False, max_episode_steps=config[\"max_timesteps\"], continuous=config[\"continuous\"], lap_complete_percent=config[\"lap_complete_percent\"])\n",
        "\tagent = DQNAgent(env, lr=config[\"lr\"], gamma=config[\"gamma\"], batch_size=config[\"batch_size\"], memory_size=config[\"memory_size\"], epsilon_start=config[\"epsilon_start\"], epsilon_end=config[\"epsilon_end\"], epsilon_decay=config[\"epsilon_decay\"])\n",
        "\t\n",
        "\tif config[\"load_save\"]:\n",
        "\t\tagent.load()\n",
        "\t\t\n",
        "\tsuccessful_run = 0\n",
        "\n",
        "\tagent.policy_net.train()\n",
        "\tfor ep in range(config[\"max_episodes\"]):\n",
        "\t\tstate, _ = env.reset(seed=config[\"seed\"])\n",
        "\t\tstate, _ = skip_zooming(env)\n",
        "\t\tstate = transform(state)\n",
        "\t\ttotal_reward = 0\n",
        "\t\trewards = []\n",
        "\t\tdone = False\n",
        "\t\tt = 0\n",
        "\n",
        "\t\twhile not done:\n",
        "\t\t\taction_idx, epsilon = agent.select_action(state)\n",
        "\t\t\tnext_state, reward, done, truncated, _ = env.step(action_idx)\n",
        "\t\t\tdone = done or truncated\n",
        "\n",
        "\t\t\tnext_state = transform(next_state)\n",
        "\n",
        "\t\t\tagent.memory.append(state, action_idx, next_state, reward, done)\n",
        "\t\t\trewards.append(reward)\n",
        "\t\t\tstate = next_state\n",
        "\t\t\ttotal_reward += reward\n",
        "\n",
        "\t\t\tloss = agent.optimize_model()\n",
        "\n",
        "\t\t\tif t % 20 == 0:\n",
        "\t\t\t\tshow_current_frame(env, {\"Episode\": ep, \"Timestep\": t, \"Loss\": loss, \"Epsilon\": epsilon})\n",
        "\n",
        "\t\t\twandb.log({\"current_reward\": total_reward, \"timestep\": t, \"loss\": loss, \"epsilon\": epsilon})\n",
        "\n",
        "\t\t\tif (len(rewards) > config[\"max_losing_step\"] and np.max(np.array(rewards[-config[\"max_losing_step\"]:])) < 0):\n",
        "\t\t\t\tbreak\n",
        "\n",
        "\t\t\tt += 1\n",
        "\n",
        "\t\tif ep % config[\"target_update_freq\"] == 0:\n",
        "\t\t\tagent.target_net.load_state_dict(agent.policy_net.state_dict())\n",
        "\n",
        "\t\tprint(f\"Episode {ep+1}, Total Reward: {total_reward}\")\n",
        "\t\timage = wandb.Image(env.render(), caption=f\"Episode {ep}\")\n",
        "\t\twandb.log({\"episode\": ep, \"reward\": total_reward, \"image\": image, \"done\": int(done) })\n",
        "\t\t\n",
        "\t\tif done == True:\n",
        "\t\t\tsuccessful_run += 1\n",
        "\n",
        "\t\t\tif successful_run >= config[\"stop_criteria_count\"]:\n",
        "\t\t\t\tbreak\n",
        "\n",
        "\t\tagent.save()\n",
        "\t\t\n",
        "\tenv.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRqpJaHEVOV9"
      },
      "source": [
        "#### Car Racing Animation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTv24Jv9VOV9"
      },
      "outputs": [],
      "source": [
        "def run_agent_and_collect_frames(agent, env, seed=42):\n",
        "  state, _ = env.reset(seed=seed)\n",
        "  done = False\n",
        "  frames = []\n",
        "\n",
        "  while not done:\n",
        "    frame = env.render()\n",
        "    frames.append(frame)\n",
        "\n",
        "    preprocessed_state = agent.preprocess_state(state)\n",
        "    action = agent.select_action(preprocessed_state)\n",
        "    next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "    done = terminated or truncated\n",
        "    state = next_state\n",
        "\n",
        "    return frames\n",
        "\n",
        "# Function to display frames as an animation using matplotlib\n",
        "def show_animation_frames(frames):\n",
        "  fig = plt.figure(figsize=(7, 5))\n",
        "  plt.axis('off')\n",
        "  im = plt.imshow(frames[0])\n",
        "\n",
        "  def animate(i):\n",
        "    im.set_data(frames[i])\n",
        "    return im,\n",
        "\n",
        "  anim = animation.FuncAnimation(fig, animate, frames=len(frames), interval=50, repeat=False)\n",
        "  plt.close(fig)\n",
        "  display(HTML(anim.to_jshtml()))\n",
        "\n",
        "# Run the episode with the trained agent\n",
        "frames = run_agent_and_collect_frames(agent, env)\n",
        "\n",
        "# Show the animation\n",
        "show_animation_frames(frames)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
